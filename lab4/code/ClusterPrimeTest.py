#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Rayé›†ç¾¤å¤§ç´ æ•°å¯»æ‰¾ä¸åˆ†è§£æµ‹è¯•ç¨‹åº
åŠŸèƒ½: å¤šèŠ‚ç‚¹é›†ç¾¤åˆ†å¸ƒå¼è®¡ç®—ï¼Œååé‡æµ‹é‡å’Œæ€§èƒ½ç›‘æ§

æœ¬ç¨‹åºä¸“é—¨ä¸ºé›†ç¾¤ç¯å¢ƒè®¾è®¡ï¼Œæ”¯æŒï¼š
1. å¤šèŠ‚ç‚¹Rayé›†ç¾¤é…ç½®
2. å®æ—¶ååé‡æµ‹é‡
3. é›†ç¾¤èµ„æºç›‘æ§
4. è´Ÿè½½å‡è¡¡ä¼˜åŒ–
5. æ€§èƒ½æŠ¥å‘Šç”Ÿæˆ

é›†ç¾¤éƒ¨ç½²è¯´æ˜ï¼š
1. åœ¨å¤´èŠ‚ç‚¹è¿è¡Œ: python ClusterPrimeTest.py --head
2. åœ¨å·¥ä½œèŠ‚ç‚¹è¿è¡Œ: python ClusterPrimeTest.py --worker --head-address=ray://head-ip:10001
3. æˆ–è€…ä½¿ç”¨Rayé›†ç¾¤å¯åŠ¨è„šæœ¬
"""

# ==================== å¯¼å…¥å¿…è¦çš„åº“ ====================
import ray
import time
import random
import math
import argparse
import json
import os
import psutil
import threading
from typing import List, Tuple, Optional, Union, Dict, Any
from dataclasses import dataclass, asdict
from datetime import datetime
import multiprocessing

# å¯¼å…¥ç´ æ•°éªŒè¯æ¨¡å—
try:
    from prime_validator import PrimeValidator
    VALIDATOR_AVAILABLE = True
    print("âœ… ç´ æ•°éªŒè¯æ¨¡å—å¯ç”¨")
except ImportError:
    VALIDATOR_AVAILABLE = False
    print("âŒ ç´ æ•°éªŒè¯æ¨¡å—ä¸å¯ç”¨")

# ==================== é›†ç¾¤é…ç½®ç±» ====================
@dataclass
class ClusterConfig:
    """é›†ç¾¤é…ç½®ç±»"""
    head_address: str = "localhost:10001"
    num_workers_per_node: int = 16
    total_nodes: int = 1
    enable_monitoring: bool = True
    log_level: str = "INFO"
    object_store_memory: int = 2000000000  # 2GB
    num_cpus: Optional[int] = None
    num_gpus: int = 0
    resources: Optional[Dict[str, float]] = None

# ==================== æ€§èƒ½ç›‘æ§ç±» ====================
@dataclass
class PerformanceMetrics:
    """æ€§èƒ½æŒ‡æ ‡æ•°æ®ç±»"""
    timestamp: float
    node_id: str
    cpu_percent: float
    memory_percent: float
    network_io: Dict[str, float]
    disk_io: Dict[str, float]
    ray_objects: int
    ray_tasks: int

class ClusterMonitor:
    """é›†ç¾¤æ€§èƒ½ç›‘æ§å™¨"""
    
    def __init__(self, config: ClusterConfig):
        self.config = config
        self.metrics_history: List[PerformanceMetrics] = []
        self.monitoring = False
        self.monitor_thread = None
    
    def start_monitoring(self):
        """å¼€å§‹ç›‘æ§"""
        if not self.config.enable_monitoring:
            return
        
        self.monitoring = True
        self.monitor_thread = threading.Thread(target=self._monitor_loop, daemon=True)
        self.monitor_thread.start()
        print("ğŸ” é›†ç¾¤ç›‘æ§å·²å¯åŠ¨")
    
    def stop_monitoring(self):
        """åœæ­¢ç›‘æ§"""
        self.monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join()
        print("ğŸ” é›†ç¾¤ç›‘æ§å·²åœæ­¢")
    
    def _monitor_loop(self):
        """ç›‘æ§å¾ªç¯"""
        while self.monitoring:
            try:
                metrics = self._collect_metrics()
                self.metrics_history.append(metrics)
                time.sleep(1)  # æ¯ç§’æ”¶é›†ä¸€æ¬¡
            except Exception as e:
                print(f"ç›‘æ§é”™è¯¯: {e}")
    
    def _collect_metrics(self) -> PerformanceMetrics:
        """æ”¶é›†æ€§èƒ½æŒ‡æ ‡"""
        cpu_percent = psutil.cpu_percent(interval=0.1)
        memory = psutil.virtual_memory()
        memory_percent = memory.percent

        net_io = psutil.net_io_counters()
        network_io = {k: float(v) for k, v in {
            'bytes_sent': net_io.bytes_sent,
            'bytes_recv': net_io.bytes_recv,
            'packets_sent': net_io.packets_sent,
            'packets_recv': net_io.packets_recv
        }.items()}

        disk_io = psutil.disk_io_counters()
        disk_metrics = {k: float(v) for k, v in {
            'read_bytes': disk_io.read_bytes if disk_io else 0,
            'write_bytes': disk_io.write_bytes if disk_io else 0,
            'read_count': disk_io.read_count if disk_io else 0,
            'write_count': disk_io.write_count if disk_io else 0
        }.items()}

        # RayæŒ‡æ ‡ï¼ˆä¸å†ç»Ÿè®¡ï¼Œè®¾ä¸º0ï¼‰
        ray_objects = 0
        ray_tasks = 0

        return PerformanceMetrics(
            timestamp=time.time(),
            node_id=str(ray.get_runtime_context().get_node_id()),
            cpu_percent=cpu_percent,
            memory_percent=memory_percent,
            network_io=network_io,
            disk_io=disk_metrics,
            ray_objects=ray_objects,
            ray_tasks=ray_tasks
        )
    
    def get_summary(self) -> Dict[str, Any]:
        """è·å–ç›‘æ§æ‘˜è¦"""
        if not self.metrics_history:
            return {}
        
        # è®¡ç®—å¹³å‡å€¼
        avg_cpu = sum(m.cpu_percent for m in self.metrics_history) / len(self.metrics_history)
        avg_memory = sum(m.memory_percent for m in self.metrics_history) / len(self.metrics_history)
        avg_ray_objects = sum(m.ray_objects for m in self.metrics_history) / len(self.metrics_history)
        
        # è®¡ç®—å³°å€¼
        max_cpu = max(m.cpu_percent for m in self.metrics_history)
        max_memory = max(m.memory_percent for m in self.metrics_history)
        
        return {
            'monitoring_duration': self.metrics_history[-1].timestamp - self.metrics_history[0].timestamp,
            'avg_cpu_percent': avg_cpu,
            'avg_memory_percent': avg_memory,
            'max_cpu_percent': max_cpu,
            'max_memory_percent': max_memory,
            'avg_ray_objects': avg_ray_objects,
            'total_metrics_collected': len(self.metrics_history)
        }

# ==================== ååé‡æµ‹é‡ç±» ====================
@dataclass
class ThroughputMetrics:
    """ååé‡æŒ‡æ ‡"""
    operation_type: str  # "prime_generation" æˆ– "factorization"
    bits: int
    total_operations: int
    successful_operations: int
    total_time: float
    throughput: float  # æ¯ç§’æ“ä½œæ•°
    avg_time_per_operation: float
    cluster_size: int
    timestamp: float

class ThroughputMeasurer:
    """ååé‡æµ‹é‡å™¨"""
    
    def __init__(self):
        self.metrics_history: List[ThroughputMetrics] = []
    
    def measure_prime_generation(self, bits: int, num_primes: int, 
                               total_time: float, successful_primes: int,
                               cluster_size: int) -> ThroughputMetrics:
        """æµ‹é‡ç´ æ•°ç”Ÿæˆååé‡"""
        throughput = successful_primes / total_time if total_time > 0 else 0
        avg_time = total_time / successful_primes if successful_primes > 0 else 0
        
        metrics = ThroughputMetrics(
            operation_type="prime_generation",
            bits=bits,
            total_operations=num_primes,
            successful_operations=successful_primes,
            total_time=total_time,
            throughput=throughput,
            avg_time_per_operation=avg_time,
            cluster_size=cluster_size,
            timestamp=time.time()
        )
        
        self.metrics_history.append(metrics)
        return metrics
    
    def measure_factorization(self, numbers: List[int], total_time: float,
                            successful_factorizations: int, cluster_size: int) -> ThroughputMetrics:
        """æµ‹é‡å¤§æ•°åˆ†è§£ååé‡"""
        throughput = successful_factorizations / total_time if total_time > 0 else 0
        avg_time = total_time / successful_factorizations if successful_factorizations > 0 else 0
        
        # ä½¿ç”¨æœ€å¤§ä½æ•°ä½œä¸ºæŒ‡æ ‡
        max_bits = max(len(bin(abs(num))) - 2 for num in numbers) if numbers else 0
        
        metrics = ThroughputMetrics(
            operation_type="factorization",
            bits=max_bits,
            total_operations=len(numbers),
            successful_operations=successful_factorizations,
            total_time=total_time,
            throughput=throughput,
            avg_time_per_operation=avg_time,
            cluster_size=cluster_size,
            timestamp=time.time()
        )
        
        self.metrics_history.append(metrics)
        return metrics
    
    def get_summary(self) -> Dict[str, Any]:
        """è·å–ååé‡æ‘˜è¦"""
        if not self.metrics_history:
            return {}
        
        # æŒ‰æ“ä½œç±»å‹åˆ†ç»„
        prime_metrics = [m for m in self.metrics_history if m.operation_type == "prime_generation"]
        factor_metrics = [m for m in self.metrics_history if m.operation_type == "factorization"]
        
        summary = {
            'total_operations': len(self.metrics_history),
            'prime_generation': {
                'total_operations': len(prime_metrics),
                'avg_throughput': sum(m.throughput for m in prime_metrics) / len(prime_metrics) if prime_metrics else 0,
                'max_throughput': max(m.throughput for m in prime_metrics) if prime_metrics else 0,
                'total_primes_generated': sum(m.successful_operations for m in prime_metrics)
            },
            'factorization': {
                'total_operations': len(factor_metrics),
                'avg_throughput': sum(m.throughput for m in factor_metrics) / len(factor_metrics) if factor_metrics else 0,
                'max_throughput': max(m.throughput for m in factor_metrics) if factor_metrics else 0,
                'total_factorizations': sum(m.successful_operations for m in factor_metrics)
            }
        }
        
        return summary

# ==================== é›†ç¾¤ç´ æ•°å·¥ä½œèŠ‚ç‚¹ ====================
@ray.remote
class ClusterPrimeWorker:
    """é›†ç¾¤ç´ æ•°å·¥ä½œèŠ‚ç‚¹ - å¢å¼ºç‰ˆ"""
    
    def __init__(self, worker_id: int, node_id: Optional[str] = None):
        self.worker_id = worker_id
        self.node_id = node_id or str(ray.get_runtime_context().get_node_id())
        self.primes_found = 0
        self.factorizations_completed = 0
        self.total_work_time = 0.0
        self.start_time = time.time()
    
    def miller_rabin_test(self, n: int, k: int = 5) -> bool:
        """Miller-Rabinç´ æ•°æµ‹è¯•ç®—æ³•"""
        if n <= 1:
            return False
        if n <= 3:
            return True
        if n % 2 == 0:
            return False
        
        r = 0
        d = n - 1
        while d % 2 == 0:
            r += 1
            d //= 2
        
        for _ in range(k):
            a = random.randrange(2, n - 1)
            x = pow(a, d, n)
            
            if x == 1 or x == n - 1:
                continue
            
            for _ in range(r - 1):
                x = (x * x) % n
                if x == n - 1:
                    break
            else:
                return False
        
        return True
    
    def generate_random_odd_number(self, bits: int) -> int:
        """ç”ŸæˆæŒ‡å®šä½æ•°çš„éšæœºå¥‡æ•°"""
        n = random.getrandbits(bits)
        n |= (1 << (bits - 1))
        n |= 1
        return n
    
    def find_prime(self, bits: int, max_attempts: int = 1000) -> Optional[int]:
        """å¯»æ‰¾æŒ‡å®šä½æ•°çš„ç´ æ•°"""
        task_start = time.time()
        attempts = 0
        
        while attempts < max_attempts:
            n = self.generate_random_odd_number(bits)
            if self.miller_rabin_test(n):
                self.primes_found += 1
                self.total_work_time += time.time() - task_start
                return n
            attempts += 1
        
        self.total_work_time += time.time() - task_start
        return None
    
    def pollard_rho_factorization(self, n: int, max_attempts: int = 10) -> List[int]:
        """Pollard's Rhoç®—æ³•è¿›è¡Œå¤§æ•°åˆ†è§£"""
        task_start = time.time()
        
        if n <= 1:
            return []
        if self.miller_rabin_test(n):
            self.factorizations_completed += 1
            self.total_work_time += time.time() - task_start
            return [n]
        
        if max_attempts <= 0:
            self.total_work_time += time.time() - task_start
            return [n]
        
        def f(x):
            return (x * x + 1) % n
        
        def gcd(a, b):
            while b:
                a, b = b, a % b
            return a
        
        x = random.randrange(2, n)
        y = x
        d = 1
        
        while d == 1:
            x = f(x)
            y = f(f(y))
            d = gcd(abs(x - y), n)
        
        if d == n:
            result = self.pollard_rho_factorization(n, max_attempts - 1)
            self.total_work_time += time.time() - task_start
            return result
        
        factors = (self.pollard_rho_factorization(d, max_attempts) + 
                  self.pollard_rho_factorization(n // d, max_attempts))
        self.factorizations_completed += 1
        self.total_work_time += time.time() - task_start
        return factors
    
    def get_detailed_stats(self) -> dict:
        """è·å–è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯"""
        uptime = time.time() - self.start_time
        return {
            'worker_id': self.worker_id,
            'node_id': self.node_id,
            'primes_found': self.primes_found,
            'factorizations_completed': self.factorizations_completed,
            'total_work_time': self.total_work_time,
            'uptime': uptime,
            'efficiency': self.total_work_time / uptime if uptime > 0 else 0
        }

# ==================== é›†ç¾¤æµ‹è¯•å¥—ä»¶ ====================
class ClusterPrimeTestSuite:
    """é›†ç¾¤ç´ æ•°æµ‹è¯•å¥—ä»¶"""
    
    def __init__(self, config: ClusterConfig):
        self.config = config
        self.monitor = ClusterMonitor(config)
        self.throughput_measurer = ThroughputMeasurer()
        self.workers = []
        self.cluster_size = 0
        
        # åˆå§‹åŒ–ç´ æ•°éªŒè¯å™¨
        if VALIDATOR_AVAILABLE:
            self.validator = PrimeValidator()
        else:
            self.validator = None
    
    def initialize_cluster(self):
        """åˆå§‹åŒ–é›†ç¾¤"""
        print("ğŸš€ åˆå§‹åŒ–Rayé›†ç¾¤...")
        
        # å¯åŠ¨ç›‘æ§
        self.monitor.start_monitoring()
        
        # ç­‰å¾…é›†ç¾¤ç¨³å®š
        time.sleep(2)
        
        # è·å–é›†ç¾¤ä¿¡æ¯
        try:
            nodes = ray.nodes()
            self.cluster_size = len(nodes)
            print(f"ğŸ“Š é›†ç¾¤ä¿¡æ¯: {self.cluster_size} ä¸ªèŠ‚ç‚¹")
            
            for node in nodes:
                node_id = node['NodeID']
                resources = node['Resources']
                print(f"  èŠ‚ç‚¹ {node_id}: CPU={resources.get('CPU', 0)}, "
                      f"å†…å­˜={resources.get('memory', 0) / 1024**3:.1f}GB")
        except Exception as e:
            print(f"âš ï¸  æ— æ³•è·å–é›†ç¾¤ä¿¡æ¯: {e}")
            self.cluster_size = 1
        
        # åˆ›å»ºå·¥ä½œèŠ‚ç‚¹
        total_workers = self.config.num_workers_per_node * self.cluster_size
        print(f"ğŸ”§ åˆ›å»º {total_workers} ä¸ªå·¥ä½œèŠ‚ç‚¹...")
        
        self.workers = []
        for i in range(total_workers):
            worker = ClusterPrimeWorker.remote(i)
            self.workers.append(worker)
        
        print("âœ… é›†ç¾¤åˆå§‹åŒ–å®Œæˆ")
    
    def find_primes_cluster(self, bits: int, num_primes: int) -> List[int]:
        """é›†ç¾¤ç´ æ•°ç”Ÿæˆ"""
        print(f"ğŸ” ä½¿ç”¨é›†ç¾¤å¯»æ‰¾ {num_primes} ä¸ª {bits} ä½ç´ æ•°...")
        
        start_time = time.time()
        
        # ä»»åŠ¡åˆ†é…
        tasks_per_worker = num_primes // len(self.workers)
        remaining_tasks = num_primes % len(self.workers)
        
        futures = []
        for i, worker in enumerate(self.workers):
            worker_tasks = tasks_per_worker + (1 if i < remaining_tasks else 0)
            for _ in range(worker_tasks):
                future = worker.find_prime.remote(bits)
                futures.append(future)
        
        # æ”¶é›†ç»“æœ
        primes = []
        for future in futures:
            prime = ray.get(future)
            if prime:
                primes.append(prime)
        
        total_time = time.time() - start_time
        
        # æµ‹é‡ååé‡
        metrics = self.throughput_measurer.measure_prime_generation(
            bits, num_primes, total_time, len(primes), self.cluster_size
        )
        
        print(f"âœ… æ‰¾åˆ° {len(primes)} ä¸ªç´ æ•°")
        print(f"â±ï¸  è€—æ—¶: {total_time:.2f} ç§’")
        print(f"ğŸš€ ååé‡: {metrics.throughput:.2f} ç´ æ•°/ç§’")
        print(f"ğŸ“Š å¹³å‡æ—¶é—´: {metrics.avg_time_per_operation:.3f} ç§’/ç´ æ•°")
        
        return primes
    
    def factorize_numbers_cluster(self, numbers: List[int]) -> List[Tuple[int, List[int]]]:
        """é›†ç¾¤å¤§æ•°åˆ†è§£"""
        print(f"ğŸ” ä½¿ç”¨é›†ç¾¤åˆ†è§£ {len(numbers)} ä¸ªæ•°...")
        
        start_time = time.time()
        
        # è½®è¯¢åˆ†é…ä»»åŠ¡
        futures = []
        for i, num in enumerate(numbers):
            worker = self.workers[i % len(self.workers)]
            future = worker.pollard_rho_factorization.remote(num)
            futures.append(future)
        
        # æ”¶é›†ç»“æœ
        factorizations = []
        for i, future in enumerate(futures):
            factors = ray.get(future)
            factorizations.append((numbers[i], factors))
        
        total_time = time.time() - start_time
        
        # æµ‹é‡ååé‡
        metrics = self.throughput_measurer.measure_factorization(
            numbers, total_time, len(factorizations), self.cluster_size
        )
        
        print(f"âœ… å®Œæˆ {len(factorizations)} ä¸ªæ•°çš„åˆ†è§£")
        print(f"â±ï¸  è€—æ—¶: {total_time:.2f} ç§’")
        print(f"ğŸš€ ååé‡: {metrics.throughput:.2f} åˆ†è§£/ç§’")
        print(f"ğŸ“Š å¹³å‡æ—¶é—´: {metrics.avg_time_per_operation:.3f} ç§’/åˆ†è§£")
        
        return factorizations
    
    def validate_generated_primes(self, primes: List[int]) -> dict:
        """éªŒè¯ç”Ÿæˆçš„ç´ æ•°"""
        if not self.validator or not primes:
            return {'validated': False, 'message': 'éªŒè¯å™¨ä¸å¯ç”¨æˆ–æ— ç´ æ•°'}
        
        print(f"\nğŸ” éªŒè¯ {len(primes)} ä¸ªç”Ÿæˆçš„ç´ æ•°...")
        validation_start = time.time()
        
        validation_results = self.validator.validate_primes_batch(primes, method="sympy")
        
        valid_primes = [r for r in validation_results if r['is_prime']]
        invalid_primes = [r for r in validation_results if not r['is_prime']]
        
        validation_time = time.time() - validation_start
        
        stats = {
            'validated': True,
            'total_primes': len(primes),
            'valid_primes': len(valid_primes),
            'invalid_primes': len(invalid_primes),
            'accuracy': len(valid_primes) / len(primes) * 100 if primes else 0,
            'validation_time': validation_time,
            'results': validation_results
        }
        
        print(f"âœ… éªŒè¯å®Œæˆï¼Œè€—æ—¶ {validation_time:.4f} ç§’")
        print(f"ğŸ“Š å‡†ç¡®ç‡: {stats['accuracy']:.2f}%")
        
        if invalid_primes:
            print(f"âš ï¸  å‘ç° {len(invalid_primes)} ä¸ªé”™è¯¯çš„ç´ æ•°")
        
        return stats
    
    def get_cluster_stats(self) -> dict:
        """è·å–é›†ç¾¤ç»Ÿè®¡ä¿¡æ¯"""
        print("\nğŸ“Š æ”¶é›†é›†ç¾¤ç»Ÿè®¡ä¿¡æ¯...")
        
        # è·å–å·¥ä½œèŠ‚ç‚¹ç»Ÿè®¡
        worker_stats = []
        for worker in self.workers:
            stats = ray.get(worker.get_detailed_stats.remote())
            worker_stats.append(stats)
        
        # è®¡ç®—æ±‡æ€»ç»Ÿè®¡
        total_primes = sum(s['primes_found'] for s in worker_stats)
        total_factorizations = sum(s['factorizations_completed'] for s in worker_stats)
        total_work_time = sum(s['total_work_time'] for s in worker_stats)
        avg_efficiency = sum(s['efficiency'] for s in worker_stats) / len(worker_stats) if worker_stats else 0
        
        # è·å–ç›‘æ§æ‘˜è¦
        monitor_summary = self.monitor.get_summary()
        
        # è·å–ååé‡æ‘˜è¦
        throughput_summary = self.throughput_measurer.get_summary()
        
        cluster_stats = {
            'cluster_size': self.cluster_size,
            'total_workers': len(self.workers),
            'worker_stats': worker_stats,
            'summary': {
                'total_primes_found': total_primes,
                'total_factorizations': total_factorizations,
                'total_work_time': total_work_time,
                'average_efficiency': avg_efficiency
            },
            'monitoring': monitor_summary,
            'throughput': throughput_summary
        }
        
        return cluster_stats
    
    def run_cluster_test(self, test_config: dict):
        """è¿è¡Œé›†ç¾¤æµ‹è¯•"""
        print("=" * 80)
        print("ğŸš€ Rayé›†ç¾¤å¤§ç´ æ•°å¯»æ‰¾ä¸åˆ†è§£æµ‹è¯•")
        print("=" * 80)
        
        # æ˜¾ç¤ºæµ‹è¯•é…ç½®
        print(f"ğŸ“‹ æµ‹è¯•é…ç½®:")
        print(f"  ç´ æ•°ç”Ÿæˆä»»åŠ¡æ•°: {test_config['num_of_generate']}")
        for i, (bits, count) in enumerate(test_config['generate_list']):
            print(f"    {i+1}. {bits}ä½ç´ æ•° x {count}ä¸ª")
        print(f"  å¤§æ•°åˆ†è§£ä»»åŠ¡æ•°: {test_config['num_of_factorize']}")
        print(f"  éªŒè¯å¯ç”¨: {'æ˜¯' if test_config['validate_enable'] else 'å¦'}")
        print()
        
        all_primes = []
        
        # ç´ æ•°ç”Ÿæˆæµ‹è¯•
        print("ğŸ” 1. ç´ æ•°ç”Ÿæˆæµ‹è¯•")
        for i, (bits, count) in enumerate(test_config['generate_list']):
            print(f"\n   ä»»åŠ¡ {i+1}: ç”Ÿæˆ {count} ä¸ª {bits} ä½ç´ æ•°")
            primes = self.find_primes_cluster(bits, count)
            all_primes.extend(primes)
            
            if test_config['validate_enable']:
                self.validate_generated_primes(primes)
        
        # å¤§æ•°åˆ†è§£æµ‹è¯•
        print(f"\nğŸ” 2. å¤§æ•°åˆ†è§£æµ‹è¯•")
        for i, num in enumerate(test_config['factorize_list']):
            print(f"\n   ä»»åŠ¡ {i+1}: åˆ†è§£æ•° {num}")
            factorizations = self.factorize_numbers_cluster([num])
            for num_result, factors in factorizations:
                print(f"   {num_result}: {factors}")
        
        # ç”Ÿæˆç´ æ•°ä¹˜ç§¯è¿›è¡Œåˆ†è§£æµ‹è¯•
        if all_primes and test_config['num_of_factorize'] > 0:
            print(f"\nğŸ” 3. ç´ æ•°ä¹˜ç§¯åˆ†è§£æµ‹è¯•")
            for i in range(min(test_config['num_of_factorize'], len(all_primes) // 2)):
                if i * 2 + 1 < len(all_primes):
                    num = all_primes[i * 2] * all_primes[i * 2 + 1]
                    print(f"\n   ä»»åŠ¡ {i+1}: åˆ†è§£ç´ æ•°ä¹˜ç§¯ {num}")
                    factorizations = self.factorize_numbers_cluster([num])
                    for num_result, factors in factorizations:
                        print(f"   {num_result}: {factors}")
        
        # ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
        print("\nğŸ“Š 4. æ€§èƒ½æŠ¥å‘Š")
        cluster_stats = self.get_cluster_stats()
        self._print_performance_report(cluster_stats)
        
        # ä¿å­˜æŠ¥å‘Š
        self._save_report(cluster_stats, test_config)
        
        print("\nâœ… é›†ç¾¤æµ‹è¯•å®Œæˆï¼")
    
    def _print_performance_report(self, stats: dict):
        """æ‰“å°æ€§èƒ½æŠ¥å‘Š"""
        print("\n" + "=" * 60)
        print("ğŸ“Š é›†ç¾¤æ€§èƒ½æŠ¥å‘Š")
        print("=" * 60)
        
        # é›†ç¾¤ä¿¡æ¯
        print(f"ğŸ¢ é›†ç¾¤è§„æ¨¡: {stats['cluster_size']} ä¸ªèŠ‚ç‚¹")
        print(f"ğŸ”§ å·¥ä½œèŠ‚ç‚¹: {stats['total_workers']} ä¸ª")
        
        # å·¥ä½œç»Ÿè®¡
        summary = stats['summary']
        print(f"\nğŸ“ˆ å·¥ä½œç»Ÿè®¡:")
        print(f"  æ€»ç´ æ•°ç”Ÿæˆ: {summary['total_primes_found']} ä¸ª")
        print(f"  æ€»åˆ†è§£ä»»åŠ¡: {summary['total_factorizations']} ä¸ª")
        print(f"  æ€»å·¥ä½œæ—¶é—´: {summary['total_work_time']:.2f} ç§’")
        print(f"  å¹³å‡æ•ˆç‡: {summary['average_efficiency']:.2%}")
        
        # ååé‡ç»Ÿè®¡
        throughput = stats['throughput']
        if throughput:
            print(f"\nğŸš€ ååé‡ç»Ÿè®¡:")
            if throughput['prime_generation']['total_operations'] > 0:
                prime_gen = throughput['prime_generation']
                print(f"  ç´ æ•°ç”Ÿæˆ:")
                print(f"    å¹³å‡ååé‡: {prime_gen['avg_throughput']:.2f} ç´ æ•°/ç§’")
                print(f"    æœ€å¤§ååé‡: {prime_gen['max_throughput']:.2f} ç´ æ•°/ç§’")
                print(f"    æ€»ç”Ÿæˆæ•°: {prime_gen['total_primes_generated']} ä¸ª")
            
            if throughput['factorization']['total_operations'] > 0:
                factor = throughput['factorization']
                print(f"  å¤§æ•°åˆ†è§£:")
                print(f"    å¹³å‡ååé‡: {factor['avg_throughput']:.2f} åˆ†è§£/ç§’")
                print(f"    æœ€å¤§ååé‡: {factor['max_throughput']:.2f} åˆ†è§£/ç§’")
                print(f"    æ€»åˆ†è§£æ•°: {factor['total_factorizations']} ä¸ª")
        
        # ç›‘æ§ç»Ÿè®¡
        monitoring = stats['monitoring']
        if monitoring:
            print(f"\nğŸ” ç³»ç»Ÿç›‘æ§:")
            print(f"  ç›‘æ§æ—¶é•¿: {monitoring['monitoring_duration']:.1f} ç§’")
            print(f"  å¹³å‡CPU: {monitoring['avg_cpu_percent']:.1f}%")
            print(f"  å¹³å‡å†…å­˜: {monitoring['avg_memory_percent']:.1f}%")
            print(f"  å³°å€¼CPU: {monitoring['max_cpu_percent']:.1f}%")
            print(f"  å³°å€¼å†…å­˜: {monitoring['max_memory_percent']:.1f}%")
            print(f"  å¹³å‡Rayå¯¹è±¡: {monitoring['avg_ray_objects']:.0f} ä¸ª")
    
    def _save_report(self, stats: dict, config: dict):
        """ä¿å­˜æ€§èƒ½æŠ¥å‘Š"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"cluster_report_{timestamp}.json"
        
        report = {
            'timestamp': timestamp,
            'config': config,
            'stats': stats
        }
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False, default=str)
            print(f"ğŸ“„ æ€§èƒ½æŠ¥å‘Šå·²ä¿å­˜: {filename}")
        except Exception as e:
            print(f"âš ï¸  ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        print("ğŸ§¹ æ¸…ç†é›†ç¾¤èµ„æº...")
        self.monitor.stop_monitoring()
        ray.shutdown()
        print("âœ… æ¸…ç†å®Œæˆ")

# ==================== ä¸»å‡½æ•° ====================
def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="Rayé›†ç¾¤å¤§ç´ æ•°æµ‹è¯•ç¨‹åº")
    parser.add_argument("--head", action="store_true", help="ä½œä¸ºå¤´èŠ‚ç‚¹è¿è¡Œ")
    parser.add_argument("--worker", action="store_true", help="ä½œä¸ºå·¥ä½œèŠ‚ç‚¹è¿è¡Œ")
    parser.add_argument("--head-address", type=str, default="localhost:10001", 
                       help="å¤´èŠ‚ç‚¹åœ°å€")
    parser.add_argument("--num-workers", type=int, default=4, 
                       help="æ¯ä¸ªèŠ‚ç‚¹çš„å·¥ä½œèŠ‚ç‚¹æ•°")
    parser.add_argument("--object-store-memory", type=int, default=2000000000,
                       help="å¯¹è±¡å­˜å‚¨å†…å­˜å¤§å°(å­—èŠ‚)")
    parser.add_argument("--config-file", type=str, help="æµ‹è¯•é…ç½®æ–‡ä»¶")
    
    args = parser.parse_args()
    
    # é…ç½®Ray
    config = ClusterConfig(
        head_address=args.head_address,
        num_workers_per_node=args.num_workers,
        object_store_memory=args.object_store_memory
    )
    
    # åˆå§‹åŒ–Ray
    if args.head:
        print("ğŸš€ å¯åŠ¨Rayå¤´èŠ‚ç‚¹...")
        # ä½¿ç”¨ç°ä»£Rayå¯åŠ¨æ–¹å¼
        ray.init(
            _system_config={"object_store_memory": config.object_store_memory},
            ignore_reinit_error=True
        )
        print("âœ… Rayå¤´èŠ‚ç‚¹å·²å¯åŠ¨ï¼Œç­‰å¾…å·¥ä½œèŠ‚ç‚¹è¿æ¥...")
        print("ğŸ’¡ æç¤º: åœ¨å·¥ä½œèŠ‚ç‚¹ä¸Šè¿è¡Œ: python ClusterPrimeTest.py --worker --head-address=<this-node-ip>:10001")
        
        # ä¿æŒå¤´èŠ‚ç‚¹è¿è¡Œ
        try:
            while True:
                time.sleep(10)
                print("ğŸ”„ å¤´èŠ‚ç‚¹è¿è¡Œä¸­...")
        except KeyboardInterrupt:
            print("\nğŸ›‘ å¤´èŠ‚ç‚¹åœæ­¢")
            ray.shutdown()
            return
            
    elif args.worker:
        print(f"ğŸ”§ è¿æ¥åˆ°Rayå¤´èŠ‚ç‚¹: {args.head_address}")
        # è¿æ¥åˆ°å·²å¯åŠ¨çš„Rayé›†ç¾¤
        ray.init(
            address=f"ray://{args.head_address}",
            ignore_reinit_error=True
        )
    else:
        # print("ğŸš€ å¯åŠ¨æœ¬åœ°Rayé›†ç¾¤...")
        # # å°è¯•è¿æ¥åˆ°ç°æœ‰é›†ç¾¤ï¼Œå¦‚æœå¤±è´¥åˆ™å¯åŠ¨æ–°çš„
        # try:
        #     ray.init(
        #         ignore_reinit_error=True,
        #         _system_config={"object_store_memory": config.object_store_memory}
        #     )
        # except Exception as e:
            # print(f"âš ï¸  å¯åŠ¨æœ¬åœ°é›†ç¾¤å¤±è´¥: {e}")
            print("ğŸ”§ å°è¯•è¿æ¥åˆ°é»˜è®¤é›†ç¾¤...")
            ray.init(
                ignore_reinit_error=True
            )
    
    # é»˜è®¤æµ‹è¯•é…ç½®
    test_config = {
        'num_of_generate': 2,
        'generate_list': [
            (512, 50),   # 512ä½ç´ æ•° x 50ä¸ª
            (1024, 20),  # 1024ä½ç´ æ•° x 20ä¸ª
        ],
        'num_of_factorize': 0,
        'factorize_list': [
            # 1000000007 * 1000000009,
            # 123456789 * 987654321,
            # 999999937 * 999999929,
        ],
        'validate_enable': True,
        'workers': config.num_workers_per_node,
        'miller_rabin_rounds': 5,
        'max_attempts': 1000,
    }
    
    # åŠ è½½é…ç½®æ–‡ä»¶
    if args.config_file and os.path.exists(args.config_file):
        try:
            with open(args.config_file, 'r', encoding='utf-8') as f:
                test_config.update(json.load(f))
            print(f"ğŸ“‹ å·²åŠ è½½é…ç½®æ–‡ä»¶: {args.config_file}")
        except Exception as e:
            print(f"âš ï¸  åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
    
    try:
        # åˆ›å»ºæµ‹è¯•å¥—ä»¶
        test_suite = ClusterPrimeTestSuite(config)
        
        # åˆå§‹åŒ–é›†ç¾¤
        test_suite.initialize_cluster()
        
        # è¿è¡Œæµ‹è¯•
        test_suite.run_cluster_test(test_config)
        
    except KeyboardInterrupt:
        print("\nâš ï¸  ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"âŒ ç¨‹åºè¿è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
    finally:
        # æ¸…ç†èµ„æº
        if 'test_suite' in locals():
            test_suite.cleanup()

if __name__ == "__main__":
    main() 